{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13708987,"sourceType":"datasetVersion","datasetId":8721046}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"941741204a003f44","cell_type":"markdown","source":"# Darlin Joel Anacicha Sanchez GR1CC\n# Ejercicio 4: Modelo Probabilístico\n\n## Objetivo de la práctica\n- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n- Comparar la recuperación con BM25 frente a TF-IDF.\n- Analizar visualmente las diferencias entre los modelos.\n- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes.","metadata":{}},{"id":"93bafe7a6a4ef9e5","cell_type":"markdown","source":"## Parte 0: Carga del Corpus","metadata":{}},{"id":"ad08bb8bd43ae327","cell_type":"code","source":"from sklearn.datasets import load_files\nimport pandas as pd\n\n# Cargar los datos\ntrain_data = load_files('/kaggle/input/dataaset/20news-bydate-train')\ntest_data = load_files('/kaggle/input/dataaset/20news-bydate-test')\n\n# Combinar documentos y etiquetas\nnewsgroupsdocs = train_data.data + test_data.data\ntargets = train_data.target.tolist() + test_data.target.tolist()\nlabels = train_data.target_names\n\nprint(len(newsgroupsdocs), \"documentos cargados\")\n\n# Limpiar textos\ndocs_limpios = [doc.decode(\"latin1\").encode(\"utf-8\",\"ignore\").decode(\"utf-8\",\"ignore\") for doc in newsgroupsdocs]\n\n# Convertir a DataFrame para ver primeros documentos\ndf = pd.DataFrame({\n    'texto': [doc[:200] for doc in docs_limpios], \n    'categoria_id': targets,\n    'categoria_nombre': [labels[i] for i in targets]\n})\n\ndf.head(100)\n","metadata":{"ExecuteTime":{"end_time":"2025-05-28T15:51:00.067230Z","start_time":"2025-05-28T15:49:34.775176Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:38.966852Z","iopub.execute_input":"2025-11-13T03:29:38.967538Z","iopub.status.idle":"2025-11-13T03:29:56.768059Z","shell.execute_reply.started":"2025-11-13T03:29:38.967508Z","shell.execute_reply":"2025-11-13T03:29:56.767108Z"}},"outputs":[{"name":"stdout","text":"18846 documentos cargados\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                texto  categoria_id  \\\n0   From: cubbie@garnet.berkeley.edu (            ...             9   \n1   From: gnelson@pion.rutgers.edu (Gregory Nelson...             4   \n2   From: crypt-comments@math.ncsu.edu\\nSubject: C...            11   \n3   From:  ()\\nSubject: Re: Quadra SCSI Problems??...             4   \n4   From: keith@cco.caltech.edu (Keith Allan Schne...             0   \n..                                                ...           ...   \n95  From: tthiel@cs.uiuc.edu (Terry Thiel)\\nSubjec...             4   \n96  From: jmeyers@ecst.csuchico.edu (Jeff Meyers)\\...             2   \n97  From: whit@carson.u.washington.edu (John Whitm...            12   \n98  From: rjwade@rainbow.ecn.purdue.edu (Robert J....             7   \n99  From: chaudhary-amar@yale.edu (Amar Chaudhary)...            18   \n\n           categoria_nombre  \n0        rec.sport.baseball  \n1     comp.sys.mac.hardware  \n2                 sci.crypt  \n3     comp.sys.mac.hardware  \n4               alt.atheism  \n..                      ...  \n95    comp.sys.mac.hardware  \n96  comp.os.ms-windows.misc  \n97          sci.electronics  \n98                rec.autos  \n99       talk.politics.misc  \n\n[100 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texto</th>\n      <th>categoria_id</th>\n      <th>categoria_nombre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: cubbie@garnet.berkeley.edu (            ...</td>\n      <td>9</td>\n      <td>rec.sport.baseball</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: gnelson@pion.rutgers.edu (Gregory Nelson...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: crypt-comments@math.ncsu.edu\\nSubject: C...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From:  ()\\nSubject: Re: Quadra SCSI Problems??...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n      <td>0</td>\n      <td>alt.atheism</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>From: tthiel@cs.uiuc.edu (Terry Thiel)\\nSubjec...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>From: jmeyers@ecst.csuchico.edu (Jeff Meyers)\\...</td>\n      <td>2</td>\n      <td>comp.os.ms-windows.misc</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>From: whit@carson.u.washington.edu (John Whitm...</td>\n      <td>12</td>\n      <td>sci.electronics</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>From: rjwade@rainbow.ecn.purdue.edu (Robert J....</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>From: chaudhary-amar@yale.edu (Amar Chaudhary)...</td>\n      <td>18</td>\n      <td>talk.politics.misc</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"id":"10f8c7f78934f497","cell_type":"markdown","source":"## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n\n### Actividad \n1. Utiliza el corpus cargado.\n2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n3. Calcula TF-IDF utilizando sklearn.\n4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos.","metadata":{}},{"id":"d2ebd9f1c1b6c787","cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport numpy as np\n\n# Usamos solo los primeros 10 documentos para que sea fácil\ndocs_demo = docs_limpios[:100]\n\n# TF\nvectorizador_tf = CountVectorizer(max_features=100)\nmatriz_tf = vectorizador_tf.fit_transform(docs_demo)\n\ntabla_tf = pd.DataFrame(matriz_tf.toarray(), columns=vectorizador_tf.get_feature_names_out())\nprint(\"=== MATRIZ TF ===\")\ndisplay(tabla_tf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.769575Z","iopub.execute_input":"2025-11-13T03:29:56.769913Z","iopub.status.idle":"2025-11-13T03:29:56.832977Z","shell.execute_reply.started":"2025-11-13T03:29:56.769893Z","shell.execute_reply":"2025-11-13T03:29:56.832176Z"}},"outputs":[{"name":"stdout","text":"=== MATRIZ TF ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    0t  1d9  3t  about  all  an  and  any  are  article  ...  when  which  \\\n0    0    0   0      0    0   0    4    0    0        1  ...     0      0   \n1    0    0   0      0    1   1    2    1    0        1  ...     0      0   \n2    0    0   0      0    2   5   45    0    4        0  ...     0      2   \n3    0    0   0      0    0   1    2    1    0        0  ...     3      1   \n4    0    0   0      0    0   0    1    0    1        0  ...     0      0   \n..  ..  ...  ..    ...  ...  ..  ...  ...  ...      ...  ...   ...    ...   \n95   0    0   0      0    0   0    9    0    0        0  ...     0      0   \n96   0    0   0      2    0   0    2    0    0        1  ...     0      0   \n97   0    0   0      0    0   0    2    1    0        2  ...     1      1   \n98   0    0   0      0    2   1    5    1    1        0  ...     2      1   \n99   0    0   0      5    3   2   19    0    7        0  ...     1      3   \n\n    who  will  with  wm  world  would  writes  you  \n0     0     2     0   0      0      0       1    0  \n1     0     1     4   0      0      2       0    1  \n2     0     0     2   0      2      0       0    1  \n3     0     2     5   0      0      2       1    0  \n4     0     1     0   0      0      0       1    1  \n..  ...   ...   ...  ..    ...    ...     ...  ...  \n95    0     1     0   0      0      0       1    0  \n96    1     0     3   0      0      0       1    0  \n97    0     2     2   0      0      1       1    0  \n98    1     2     5   0      0      0       0    2  \n99    0     2     4   0      2      0       0    7  \n\n[100 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0t</th>\n      <th>1d9</th>\n      <th>3t</th>\n      <th>about</th>\n      <th>all</th>\n      <th>an</th>\n      <th>and</th>\n      <th>any</th>\n      <th>are</th>\n      <th>article</th>\n      <th>...</th>\n      <th>when</th>\n      <th>which</th>\n      <th>who</th>\n      <th>will</th>\n      <th>with</th>\n      <th>wm</th>\n      <th>world</th>\n      <th>would</th>\n      <th>writes</th>\n      <th>you</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5</td>\n      <td>45</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 100 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"id":"44463902-8e99-4fb8-a583-ec825d8220b3","cell_type":"code","source":"# DF (Document Frequency)\ndf_valores = np.sum(matriz_tf.toarray() > 0, axis=0)\ntabla_df = pd.Series(df_valores, index=vectorizador_tf.get_feature_names_out(), name=\"DF\")\nprint(\"\\n=== FRECUENCIA DE DOCUMENTOS (DF) ===\")\ndisplay(tabla_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.833865Z","iopub.execute_input":"2025-11-13T03:29:56.834174Z","iopub.status.idle":"2025-11-13T03:29:56.843492Z","shell.execute_reply.started":"2025-11-13T03:29:56.834154Z","shell.execute_reply":"2025-11-13T03:29:56.842562Z"}},"outputs":[{"name":"stdout","text":"\n=== FRECUENCIA DE DOCUMENTOS (DF) ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0t         1\n1d9        1\n3t         1\nabout     33\nall       41\n          ..\nwm         2\nworld     17\nwould     41\nwrites    50\nyou       49\nName: DF, Length: 100, dtype: int64"},"metadata":{}}],"execution_count":13},{"id":"843470f3-d6a8-4712-bba4-b4f31b3910db","cell_type":"code","source":"# TF-IDF\nvectorizador_tfidf = TfidfVectorizer(max_features=100)\nmatriz_tfidf = vectorizador_tfidf.fit_transform(docs_demo)\n\ntabla_tfidf = pd.DataFrame(matriz_tfidf.toarray(), columns=vectorizador_tfidf.get_feature_names_out())\nprint(\"\\n=== MATRIZ TF-IDF ===\")\ndisplay(tabla_tfidf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.845824Z","iopub.execute_input":"2025-11-13T03:29:56.846142Z","iopub.status.idle":"2025-11-13T03:29:56.927165Z","shell.execute_reply.started":"2025-11-13T03:29:56.846121Z","shell.execute_reply":"2025-11-13T03:29:56.926376Z"}},"outputs":[{"name":"stdout","text":"\n=== MATRIZ TF-IDF ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     0t  1d9   3t     about       all        an       and       any       are  \\\n0   0.0  0.0  0.0  0.000000  0.000000  0.000000  0.284781  0.000000  0.000000   \n1   0.0  0.0  0.0  0.000000  0.060933  0.055930  0.073854  0.060170  0.000000   \n2   0.0  0.0  0.0  0.000000  0.031168  0.071523  0.425000  0.000000  0.055246   \n3   0.0  0.0  0.0  0.000000  0.000000  0.045326  0.059852  0.048762  0.000000   \n4   0.0  0.0  0.0  0.000000  0.000000  0.000000  0.079233  0.000000  0.115870   \n..  ...  ...  ...       ...       ...       ...       ...       ...       ...   \n95  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.581133  0.000000  0.000000   \n96  0.0  0.0  0.0  0.225199  0.000000  0.000000  0.122670  0.000000  0.000000   \n97  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.083904  0.068357  0.000000   \n98  0.0  0.0  0.0  0.000000  0.114241  0.052430  0.173082  0.056404  0.050623   \n99  0.0  0.0  0.0  0.128597  0.069352  0.042439  0.266186  0.000000  0.143414   \n\n     article  ...      when     which       who      will      with   wm  \\\n0   0.109123  ...  0.000000  0.000000  0.000000  0.232013  0.000000  0.0   \n1   0.056600  ...  0.000000  0.000000  0.000000  0.060170  0.199611  0.0   \n2   0.000000  ...  0.000000  0.036754  0.000000  0.000000  0.025526  0.0   \n3   0.000000  ...  0.189079  0.058231  0.000000  0.097524  0.202208  0.0   \n4   0.000000  ...  0.000000  0.000000  0.000000  0.129104  0.000000  0.0   \n..       ...  ...       ...       ...       ...       ...       ...  ...   \n95  0.000000  ...  0.000000  0.000000  0.000000  0.105212  0.000000  0.0   \n96  0.094010  ...  0.000000  0.000000  0.125027  0.000000  0.248661  0.0   \n97  0.128603  ...  0.088354  0.081631  0.000000  0.136715  0.113387  0.0   \n98  0.000000  ...  0.145809  0.067357  0.070563  0.112809  0.233901  0.0   \n99  0.000000  ...  0.029506  0.081782  0.000000  0.045655  0.075730  0.0   \n\n       world     would    writes       you  \n0   0.000000  0.000000  0.105330  0.000000  \n1   0.000000  0.121867  0.000000  0.055275  \n2   0.045235  0.000000  0.000000  0.014137  \n3   0.000000  0.098762  0.044274  0.000000  \n4   0.000000  0.000000  0.117222  0.118601  \n..       ...       ...       ...       ...  \n95  0.000000  0.000000  0.095529  0.000000  \n96  0.000000  0.000000  0.090742  0.000000  \n97  0.000000  0.069225  0.062066  0.000000  \n98  0.000000  0.000000  0.000000  0.103632  \n99  0.067101  0.000000  0.000000  0.146794  \n\n[100 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0t</th>\n      <th>1d9</th>\n      <th>3t</th>\n      <th>about</th>\n      <th>all</th>\n      <th>an</th>\n      <th>and</th>\n      <th>any</th>\n      <th>are</th>\n      <th>article</th>\n      <th>...</th>\n      <th>when</th>\n      <th>which</th>\n      <th>who</th>\n      <th>will</th>\n      <th>with</th>\n      <th>wm</th>\n      <th>world</th>\n      <th>would</th>\n      <th>writes</th>\n      <th>you</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.284781</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.109123</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.232013</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.105330</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.060933</td>\n      <td>0.055930</td>\n      <td>0.073854</td>\n      <td>0.060170</td>\n      <td>0.000000</td>\n      <td>0.056600</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.060170</td>\n      <td>0.199611</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.121867</td>\n      <td>0.000000</td>\n      <td>0.055275</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.031168</td>\n      <td>0.071523</td>\n      <td>0.425000</td>\n      <td>0.000000</td>\n      <td>0.055246</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.036754</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.025526</td>\n      <td>0.0</td>\n      <td>0.045235</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.014137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.045326</td>\n      <td>0.059852</td>\n      <td>0.048762</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.189079</td>\n      <td>0.058231</td>\n      <td>0.000000</td>\n      <td>0.097524</td>\n      <td>0.202208</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.098762</td>\n      <td>0.044274</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.079233</td>\n      <td>0.000000</td>\n      <td>0.115870</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.129104</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.117222</td>\n      <td>0.118601</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.581133</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.105212</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.095529</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.225199</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.122670</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.094010</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.125027</td>\n      <td>0.000000</td>\n      <td>0.248661</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.090742</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.083904</td>\n      <td>0.068357</td>\n      <td>0.000000</td>\n      <td>0.128603</td>\n      <td>...</td>\n      <td>0.088354</td>\n      <td>0.081631</td>\n      <td>0.000000</td>\n      <td>0.136715</td>\n      <td>0.113387</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.069225</td>\n      <td>0.062066</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.114241</td>\n      <td>0.052430</td>\n      <td>0.173082</td>\n      <td>0.056404</td>\n      <td>0.050623</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.145809</td>\n      <td>0.067357</td>\n      <td>0.070563</td>\n      <td>0.112809</td>\n      <td>0.233901</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.103632</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.128597</td>\n      <td>0.069352</td>\n      <td>0.042439</td>\n      <td>0.266186</td>\n      <td>0.000000</td>\n      <td>0.143414</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.029506</td>\n      <td>0.081782</td>\n      <td>0.000000</td>\n      <td>0.045655</td>\n      <td>0.075730</td>\n      <td>0.0</td>\n      <td>0.067101</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.146794</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 100 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"id":"64491bce5361e8b3","cell_type":"markdown","source":"## Parte 2: Ranking de documentos usando TF-IDF\n\n### Actividad \n\n1. Dada una consulta, construye el vector de consulta\n2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n3. Genera un ranking de los documentos ordenados por relevancia.\n4. Muestra los resultados en una tabla.","metadata":{}},{"id":"9d082c4a156b9554","cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\nconsulta = \"computadoras y gráficos\"\nvector_consulta = vectorizador_tfidf.transform([consulta])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.928143Z","iopub.execute_input":"2025-11-13T03:29:56.928525Z","iopub.status.idle":"2025-11-13T03:29:56.933982Z","shell.execute_reply.started":"2025-11-13T03:29:56.928497Z","shell.execute_reply":"2025-11-13T03:29:56.933101Z"}},"outputs":[],"execution_count":15},{"id":"5b6f05a7-1ca3-4084-8df0-4a797e73443e","cell_type":"code","source":"similitud = cosine_similarity(vector_consulta, matriz_tfidf).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.934998Z","iopub.execute_input":"2025-11-13T03:29:56.935726Z","iopub.status.idle":"2025-11-13T03:29:56.951934Z","shell.execute_reply.started":"2025-11-13T03:29:56.935674Z","shell.execute_reply":"2025-11-13T03:29:56.951184Z"}},"outputs":[],"execution_count":16},{"id":"6d5de59378900ca","cell_type":"code","source":"ranking = similitud.argsort()[::-1][:10]  # top 10C documentos\n\nresultado = pd.DataFrame({\n    \"Documento\": ranking,\n    \"Puntaje\": similitud[ranking],\n    \"Categoria\": [labels[targets[i]] for i in ranking],\n    \"Texto\": [docs_demo[i][:120] + \"...\" for i in ranking]\n})\n\nprint(\"\\n=== RANKING DE DOCUMENTOS POR RELEVANCIA ===\")\ndisplay(resultado)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:29:56.952902Z","iopub.execute_input":"2025-11-13T03:29:56.953317Z","iopub.status.idle":"2025-11-13T03:29:56.975907Z","shell.execute_reply.started":"2025-11-13T03:29:56.953296Z","shell.execute_reply":"2025-11-13T03:29:56.974751Z"}},"outputs":[{"name":"stdout","text":"\n=== RANKING DE DOCUMENTOS POR RELEVANCIA ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Documento  Puntaje                Categoria  \\\n0         99      0.0       talk.politics.misc   \n1         36      0.0                  sci.med   \n2         26      0.0                sci.space   \n3         27      0.0                rec.autos   \n4         28      0.0  comp.os.ms-windows.misc   \n5         29      0.0            comp.graphics   \n6         30      0.0                sci.crypt   \n7         31      0.0           comp.windows.x   \n8         32      0.0    comp.sys.mac.hardware   \n9         33      0.0              alt.atheism   \n\n                                               Texto  \n0  From: chaudhary-amar@yale.edu (Amar Chaudhary)...  \n1  From: wcsbeau@alfred.carleton.ca (OPIRG)\\nSubj...  \n2  From: aws@iti.org (Allen W. Sherzer)\\nSubject:...  \n3  From: sheinfel@ssd.comm.mot.com (Aviad Sheinfe...  \n4  From: ac151@Freenet.carleton.ca (David Clarke)...  \n5  From: davidr@rincon.ema.rockwell.com (David J....  \n6  From: silly@ugcs.caltech.edu (Brad Threatt)\\nS...  \n7  From: aa894@Freenet.carleton.ca (Terry MacLean...  \n8  Distribution: world\\nFrom: Thomas_n.a._Krebs@m...  \n9  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Documento</th>\n      <th>Puntaje</th>\n      <th>Categoria</th>\n      <th>Texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>99</td>\n      <td>0.0</td>\n      <td>talk.politics.misc</td>\n      <td>From: chaudhary-amar@yale.edu (Amar Chaudhary)...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>0.0</td>\n      <td>sci.med</td>\n      <td>From: wcsbeau@alfred.carleton.ca (OPIRG)\\nSubj...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>0.0</td>\n      <td>sci.space</td>\n      <td>From: aws@iti.org (Allen W. Sherzer)\\nSubject:...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>0.0</td>\n      <td>rec.autos</td>\n      <td>From: sheinfel@ssd.comm.mot.com (Aviad Sheinfe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>0.0</td>\n      <td>comp.os.ms-windows.misc</td>\n      <td>From: ac151@Freenet.carleton.ca (David Clarke)...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>29</td>\n      <td>0.0</td>\n      <td>comp.graphics</td>\n      <td>From: davidr@rincon.ema.rockwell.com (David J....</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30</td>\n      <td>0.0</td>\n      <td>sci.crypt</td>\n      <td>From: silly@ugcs.caltech.edu (Brad Threatt)\\nS...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>31</td>\n      <td>0.0</td>\n      <td>comp.windows.x</td>\n      <td>From: aa894@Freenet.carleton.ca (Terry MacLean...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32</td>\n      <td>0.0</td>\n      <td>comp.sys.mac.hardware</td>\n      <td>Distribution: world\\nFrom: Thomas_n.a._Krebs@m...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33</td>\n      <td>0.0</td>\n      <td>alt.atheism</td>\n      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"id":"40884ff6-0bcf-48d1-9e03-91a1c2dc4964","cell_type":"markdown","source":"## Forma Manual","metadata":{}},{"id":"64c17562-c063-4187-9dce-1fcd8031fba0","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom math import log\nimport re\nfrom sklearn.datasets import load_files\n\n# === 1. Cargar datos ===\ntrain_data = load_files('/kaggle/input/dataaset/20news-bydate-train')\ntest_data = load_files('/kaggle/input/dataaset/20news-bydate-test')\n\nnewsgroupsdocs = train_data.data + test_data.data\ntargets = train_data.target.tolist() + test_data.target.tolist()\nlabels = train_data.target_names\n\nprint(len(newsgroupsdocs), \"documentos cargados\")\n\n# === 2. Limpiar texto ===\ndocs_limpios = []\nfor doc in newsgroupsdocs:\n    # Intentamos decodificar\n    try:\n        texto = doc.decode(\"latin1\")\n    except:\n        texto = str(doc)\n    # Expresión regular: solo letras y espacios\n    texto = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑ\\s]', ' ', texto)\n    texto = texto.lower()\n    texto = re.sub(r'\\b[a-zñáéíóú]{1,2}\\b', ' ', texto)\n    texto = re.sub(r'\\s+', ' ', texto).strip()\n    docs_limpios.append(texto)\n\n# Para hacerlo más liviano, usamos solo los primeros 100 documentos\ncorpus = docs_limpios[:100]\nprint(\"Documentos en corpus:\", len(corpus))\n\n# === 3. Crear vocabulario ===\ntexto_total = \" \".join(corpus)\nvocabulario = list(set(texto_total.split()))\nprint(\"Tamaño del vocabulario:\", len(vocabulario))\n\n# === 4. Calcular TF ===\ndef calcular_tf(doc, vocabulario):\n    palabras = doc.split()\n    tf = []\n    for palabra in vocabulario:\n        tf.append(palabras.count(palabra))\n    return np.array(tf)\n\nmatriz_tf = np.array([calcular_tf(doc, vocabulario) for doc in corpus])\nprint(\"Matriz TF lista:\", matriz_tf.shape)\n\n# === 5. Calcular DF ===\ndf = np.sum(matriz_tf > 0, axis=0)\nprint(\"Frecuencia DF calculada:\", df.shape)\n\n# === 6. Calcular IDF ===\nN = len(corpus)\nidf = np.log(N / (df + 1))  # +1 para evitar dividir por cero\n\n# === 7. Calcular TF-IDF manualmente ===\nmatriz_tfidf = matriz_tf * idf\n\n# === 8. Mostrar resultados ===\ndf_tfidf = pd.DataFrame(matriz_tfidf, columns=vocabulario)\nprint(\"\\n=== MATRIZ TF-IDF (primeras filas) ===\")\ndisplay(df_tfidf.head())\n\nprint(\"\\nTF del primer documento:\\n\", matriz_tf[0][:100])\nprint(\"\\nIDF de las primeras 20 palabras:\\n\", idf[:100])\nprint(\"\\nTF-IDF del primer documento:\\n\", matriz_tfidf[0][:100])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:36:19.412422Z","iopub.execute_input":"2025-11-13T03:36:19.412716Z","iopub.status.idle":"2025-11-13T03:36:40.335331Z","shell.execute_reply.started":"2025-11-13T03:36:19.412696Z","shell.execute_reply":"2025-11-13T03:36:40.334486Z"}},"outputs":[{"name":"stdout","text":"18846 documentos cargados\nDocumentos en corpus: 100\nTamaño del vocabulario: 6334\nMatriz TF lista: (100, 6334)\nFrecuencia DF calculada: (6334,)\n\n=== MATRIZ TF-IDF (primeras filas) ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   excitotoxic   happens  eisenhower   contain  randy  disk  nus  scam  \\\n0          0.0  0.000000         0.0  0.000000    0.0   0.0  0.0   0.0   \n1          0.0  0.000000         0.0  0.000000    0.0   0.0  0.0   0.0   \n2          0.0  0.000000         0.0  3.506558    0.0   0.0  0.0   0.0   \n3          0.0  2.995732         0.0  0.000000    0.0   0.0  0.0   0.0   \n4          0.0  0.000000         0.0  0.000000    0.0   0.0  0.0   0.0   \n\n   charley  complicated  ...  relativly  reality  county  departement  myths  \\\n0      0.0          0.0  ...        0.0      0.0     0.0          0.0    0.0   \n1      0.0          0.0  ...        0.0      0.0     0.0          0.0    0.0   \n2      0.0          0.0  ...        0.0      0.0     0.0          0.0    0.0   \n3      0.0          0.0  ...        0.0      0.0     0.0          0.0    0.0   \n4      0.0          0.0  ...        0.0      0.0     0.0          0.0    0.0   \n\n       via  surviving       cam     ftpmd  smart  \n0  0.00000        0.0  0.000000  0.000000    0.0  \n1  0.00000        0.0  0.000000  0.000000    0.0  \n2  2.65926        0.0  7.824046  3.912023    0.0  \n3  0.00000        0.0  0.000000  0.000000    0.0  \n4  0.00000        0.0  0.000000  0.000000    0.0  \n\n[5 rows x 6334 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>excitotoxic</th>\n      <th>happens</th>\n      <th>eisenhower</th>\n      <th>contain</th>\n      <th>randy</th>\n      <th>disk</th>\n      <th>nus</th>\n      <th>scam</th>\n      <th>charley</th>\n      <th>complicated</th>\n      <th>...</th>\n      <th>relativly</th>\n      <th>reality</th>\n      <th>county</th>\n      <th>departement</th>\n      <th>myths</th>\n      <th>via</th>\n      <th>surviving</th>\n      <th>cam</th>\n      <th>ftpmd</th>\n      <th>smart</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.506558</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.65926</td>\n      <td>0.0</td>\n      <td>7.824046</td>\n      <td>3.912023</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>2.995732</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 6334 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nTF del primer documento:\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n\nIDF de las primeras 20 palabras:\n [3.91202301 2.99573227 3.91202301 3.5065579  3.91202301 3.21887582\n 3.91202301 3.91202301 3.91202301 3.5065579  3.21887582 3.21887582\n 3.91202301 3.91202301 3.21887582 3.91202301 3.91202301 3.91202301\n 3.91202301 3.91202301]\n\nTF-IDF del primer documento:\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","output_type":"stream"}],"execution_count":22},{"id":"dc3a7ea4-1561-405c-b8bf-721442772c6b","cell_type":"code","source":"#  Vectorizar la consulta (manual)\n\nconsulta_texto = \"computadoras y gráficos\"   # tu consulta\nconsulta_palabras = consulta_texto.lower().replace(\".\", \" \").replace(\",\", \" \").split()\n\n# TF de la consulta (en el vocabulario)\ntf_consulta = np.array([consulta_palabras.count(pal) for pal in vocabulario], dtype=float)\n\n# TF-IDF de la consulta: TF * IDF (misma fórmula que usamos para docs)\nvec_consulta = tf_consulta * idf  # vector tamaño = vocabulario\n\n\n#  Similitud coseno (manual) entre vec_consulta y cada documento\n\n# norma del vector consulta\nnorm_consulta = np.linalg.norm(vec_consulta)\n\n# norma de cada documento (usamos matriz_tfidf ya calculada)\nnorms_docs = np.linalg.norm(matriz_tfidf, axis=1)\n\n# evitar división por cero: si alguna norma es 0, la ponemos muy pequeña\neps = 1e-12\nnorms_docs = np.where(norms_docs == 0, eps, norms_docs)\nnorm_consulta = norm_consulta if norm_consulta != 0 else eps\n\n# producto punto entre consulta y cada documento\npuntos = matriz_tfidf.dot(vec_consulta)  # (n_docs,)\n\n# similitud coseno\nsimilitudes = puntos / (norms_docs * norm_consulta)\n\n\n#  Ranking: ordenar documentos por similitud (de mayor a menor)\n\ntop_k = 10\nindices_ordenados = np.argsort(similitudes)[::-1][:top_k]\n\n# Para mostrar categoría y texto, necesitamos los índices reales en el dataset.\n# En nuestro ejemplo usamos `corpus = docs_limpios[:10]`, por lo tanto los índices reales son 0..9.\n# Si tu corpus es una porción distinta, ajusta `indice_real = indice_offset + i`.\n# Aquí asumimos offset = 0:\noffset = 0\n\nfilas_resultado = []\nfor idx in indices_ordenados:\n    idx_real = offset + idx\n    categoria = labels[targets[idx_real]] if idx_real < len(targets) else \"desconocida\"\n    texto_snippet = corpus[idx][:200]  # usa corpus (documentos usados en la demo)\n    filas_resultado.append({\n        \"Indice_local\": int(idx),               # índice dentro de corpus usado\n        \"Indice_global\": int(idx_real),         # índice relativo al dataset completo\n        \"Puntaje_coseno\": float(similitudes[idx]),\n        \"Categoria\": categoria,\n        \"Texto (inicio)\": texto_snippet\n    })\n\ntabla_resultados = pd.DataFrame(filas_resultado)\nprint(\"=== RANKING MANUAL (similitud coseno) ===\")\ndisplay(tabla_resultados)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T03:36:55.046985Z","iopub.execute_input":"2025-11-13T03:36:55.048405Z","iopub.status.idle":"2025-11-13T03:36:55.069719Z","shell.execute_reply.started":"2025-11-13T03:36:55.048372Z","shell.execute_reply":"2025-11-13T03:36:55.068759Z"}},"outputs":[{"name":"stdout","text":"=== RANKING MANUAL (similitud coseno) ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Indice_local  Indice_global  Puntaje_coseno                Categoria  \\\n0            99             99             0.0       talk.politics.misc   \n1            36             36             0.0                  sci.med   \n2            26             26             0.0                sci.space   \n3            27             27             0.0                rec.autos   \n4            28             28             0.0  comp.os.ms-windows.misc   \n5            29             29             0.0            comp.graphics   \n6            30             30             0.0                sci.crypt   \n7            31             31             0.0           comp.windows.x   \n8            32             32             0.0    comp.sys.mac.hardware   \n9            33             33             0.0              alt.atheism   \n\n                                      Texto (inicio)  \n0  from chaudhary amar yale edu amar chaudhary su...  \n1  from wcsbeau alfred carleton opirg subject msg...  \n2  from aws iti org allen sherzer subject sixty t...  \n3  from sheinfel ssd comm mot com aviad sheinfeld...  \n4  from freenet carleton david clarke subject dos...  \n5  from davidr rincon ema rockwell com david ray ...  \n6  from silly ugcs caltech edu brad threatt subje...  \n7  from freenet carleton terry maclean subject ho...  \n8  distribution world from thomas krebs mcontent ...  \n9  from dbstu benedikt rosenau subject anecdote a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Indice_local</th>\n      <th>Indice_global</th>\n      <th>Puntaje_coseno</th>\n      <th>Categoria</th>\n      <th>Texto (inicio)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>99</td>\n      <td>99</td>\n      <td>0.0</td>\n      <td>talk.politics.misc</td>\n      <td>from chaudhary amar yale edu amar chaudhary su...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36</td>\n      <td>36</td>\n      <td>0.0</td>\n      <td>sci.med</td>\n      <td>from wcsbeau alfred carleton opirg subject msg...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>26</td>\n      <td>0.0</td>\n      <td>sci.space</td>\n      <td>from aws iti org allen sherzer subject sixty t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>27</td>\n      <td>0.0</td>\n      <td>rec.autos</td>\n      <td>from sheinfel ssd comm mot com aviad sheinfeld...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>28</td>\n      <td>0.0</td>\n      <td>comp.os.ms-windows.misc</td>\n      <td>from freenet carleton david clarke subject dos...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>29</td>\n      <td>29</td>\n      <td>0.0</td>\n      <td>comp.graphics</td>\n      <td>from davidr rincon ema rockwell com david ray ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30</td>\n      <td>30</td>\n      <td>0.0</td>\n      <td>sci.crypt</td>\n      <td>from silly ugcs caltech edu brad threatt subje...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>31</td>\n      <td>31</td>\n      <td>0.0</td>\n      <td>comp.windows.x</td>\n      <td>from freenet carleton terry maclean subject ho...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32</td>\n      <td>32</td>\n      <td>0.0</td>\n      <td>comp.sys.mac.hardware</td>\n      <td>distribution world from thomas krebs mcontent ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33</td>\n      <td>33</td>\n      <td>0.0</td>\n      <td>alt.atheism</td>\n      <td>from dbstu benedikt rosenau subject anecdote a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23}]}